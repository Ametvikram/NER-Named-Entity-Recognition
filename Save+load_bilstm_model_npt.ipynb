{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Model without CRF\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "data = pd.read_csv('nptdata.csv', encoding='latin1', sep = ',')\n",
    "data = data.fillna(method=\"ffill\")\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "sentences = getter.sentences\n",
    "max_len = 50\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "#from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1711 samples, validate on 191 samples\n",
      "Epoch 1/100\n",
      "1711/1711 [==============================] - 12s - loss: 0.4295 - acc: 0.9333 - val_loss: 0.2487 - val_acc: 0.9485\n",
      "Epoch 2/100\n",
      "1711/1711 [==============================] - 10s - loss: 0.2198 - acc: 0.9493 - val_loss: 0.2034 - val_acc: 0.9486\n",
      "Epoch 3/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.1601 - acc: 0.9557 - val_loss: 0.1429 - val_acc: 0.9617\n",
      "Epoch 4/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.1158 - acc: 0.9658 - val_loss: 0.1166 - val_acc: 0.9664\n",
      "Epoch 5/100\n",
      "1711/1711 [==============================] - 12s - loss: 0.0932 - acc: 0.9733 - val_loss: 0.0956 - val_acc: 0.9743\n",
      "Epoch 6/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0755 - acc: 0.9790 - val_loss: 0.0819 - val_acc: 0.9791\n",
      "Epoch 7/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0595 - acc: 0.9836 - val_loss: 0.0696 - val_acc: 0.9828\n",
      "Epoch 8/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0463 - acc: 0.9883 - val_loss: 0.0551 - val_acc: 0.9876\n",
      "Epoch 9/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0363 - acc: 0.9908 - val_loss: 0.0481 - val_acc: 0.9890\n",
      "Epoch 10/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0283 - acc: 0.9935 - val_loss: 0.0413 - val_acc: 0.9893TA: 5s - loss: 0.0283 - acc: 0.9 - ETA: 4s - lo\n",
      "Epoch 11/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0222 - acc: 0.9947 - val_loss: 0.0370 - val_acc: 0.9903\n",
      "Epoch 12/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0182 - acc: 0.9955 - val_loss: 0.0345 - val_acc: 0.9917\n",
      "Epoch 13/100\n",
      "1711/1711 [==============================] - 10s - loss: 0.0142 - acc: 0.9965 - val_loss: 0.0326 - val_acc: 0.9921\n",
      "Epoch 14/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0120 - acc: 0.9971 - val_loss: 0.0310 - val_acc: 0.9925\n",
      "Epoch 15/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0102 - acc: 0.9975 - val_loss: 0.0265 - val_acc: 0.9935\n",
      "Epoch 16/100\n",
      "1711/1711 [==============================] - 10s - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0276 - val_acc: 0.9937\n",
      "Epoch 17/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0072 - acc: 0.9983 - val_loss: 0.0265 - val_acc: 0.9941\n",
      "Epoch 18/100\n",
      "1711/1711 [==============================] - 12s - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0240 - val_acc: 0.9943\n",
      "Epoch 19/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0272 - val_acc: 0.9942\n",
      "Epoch 20/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0238 - val_acc: 0.9953\n",
      "Epoch 21/100\n",
      "1711/1711 [==============================] - 17s - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0217 - val_acc: 0.9947\n",
      "Epoch 22/100\n",
      "1711/1711 [==============================] - 20s - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0211 - val_acc: 0.9955\n",
      "Epoch 23/100\n",
      "1711/1711 [==============================] - 19s - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0229 - val_acc: 0.9957\n",
      "Epoch 24/100\n",
      "1711/1711 [==============================] - 20s - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0205 - val_acc: 0.9956\n",
      "Epoch 25/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0222 - val_acc: 0.9958\n",
      "Epoch 26/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0234 - val_acc: 0.9956\n",
      "Epoch 27/100\n",
      "1711/1711 [==============================] - 10s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0234 - val_acc: 0.9959\n",
      "Epoch 28/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0223 - val_acc: 0.9957\n",
      "Epoch 29/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0216 - val_acc: 0.9958\n",
      "Epoch 30/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0249 - val_acc: 0.9957\n",
      "Epoch 31/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0228 - val_acc: 0.9961\n",
      "Epoch 32/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0234 - val_acc: 0.9963\n",
      "Epoch 33/100\n",
      "1711/1711 [==============================] - 11s - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0243 - val_acc: 0.9962\n",
      "Epoch 34/100\n",
      "1711/1711 [==============================] - 11s - loss: 8.7521e-04 - acc: 0.9998 - val_loss: 0.0265 - val_acc: 0.9959\n",
      "Epoch 35/100\n",
      "1711/1711 [==============================] - 10s - loss: 7.1848e-04 - acc: 0.9998 - val_loss: 0.0246 - val_acc: 0.9963\n",
      "Epoch 36/100\n",
      "1711/1711 [==============================] - 11s - loss: 8.5080e-04 - acc: 0.9998 - val_loss: 0.0235 - val_acc: 0.9962\n",
      "Epoch 37/100\n",
      "1711/1711 [==============================] - 10s - loss: 8.1412e-04 - acc: 0.9997 - val_loss: 0.0257 - val_acc: 0.9961\n",
      "Epoch 38/100\n",
      "1711/1711 [==============================] - 11s - loss: 7.9052e-04 - acc: 0.9997 - val_loss: 0.0253 - val_acc: 0.9961\n",
      "Epoch 39/100\n",
      "1711/1711 [==============================] - 11s - loss: 6.6347e-04 - acc: 0.9998 - val_loss: 0.0254 - val_acc: 0.9959\n",
      "Epoch 40/100\n",
      "1711/1711 [==============================] - 11s - loss: 6.2162e-04 - acc: 0.9999 - val_loss: 0.0277 - val_acc: 0.9956\n",
      "Epoch 41/100\n",
      "1711/1711 [==============================] - 11s - loss: 7.5777e-04 - acc: 0.9998 - val_loss: 0.0234 - val_acc: 0.9962\n",
      "Epoch 42/100\n",
      "1711/1711 [==============================] - 11s - loss: 6.4000e-04 - acc: 0.9998 - val_loss: 0.0248 - val_acc: 0.9958\n",
      "Epoch 43/100\n",
      "1711/1711 [==============================] - 11s - loss: 6.2209e-04 - acc: 0.9998 - val_loss: 0.0245 - val_acc: 0.9964\n",
      "Epoch 44/100\n",
      "1711/1711 [==============================] - 11s - loss: 6.2989e-04 - acc: 0.9998 - val_loss: 0.0238 - val_acc: 0.9966\n",
      "Epoch 45/100\n",
      "1711/1711 [==============================] - 11s - loss: 5.1972e-04 - acc: 0.9998 - val_loss: 0.0244 - val_acc: 0.9961\n",
      "Epoch 46/100\n",
      "1711/1711 [==============================] - 11s - loss: 5.7678e-04 - acc: 0.9998 - val_loss: 0.0285 - val_acc: 0.9957\n",
      "Epoch 47/100\n",
      "1711/1711 [==============================] - 11s - loss: 4.1148e-04 - acc: 0.9999 - val_loss: 0.0258 - val_acc: 0.9960\n",
      "Epoch 48/100\n",
      "1711/1711 [==============================] - 11s - loss: 6.1734e-04 - acc: 0.9998 - val_loss: 0.0277 - val_acc: 0.9961\n",
      "Epoch 49/100\n",
      "1711/1711 [==============================] - 11s - loss: 5.1595e-04 - acc: 0.9998 - val_loss: 0.0255 - val_acc: 0.9960\n",
      "Epoch 50/100\n",
      "1711/1711 [==============================] - 11s - loss: 5.0736e-04 - acc: 0.9999 - val_loss: 0.0264 - val_acc: 0.9962\n",
      "Epoch 51/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.7407e-04 - acc: 0.9999 - val_loss: 0.0264 - val_acc: 0.9961\n",
      "Epoch 52/100\n",
      "1711/1711 [==============================] - 11s - loss: 4.5246e-04 - acc: 0.9999 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "Epoch 53/100\n",
      "1711/1711 [==============================] - 10s - loss: 4.8156e-04 - acc: 0.9998 - val_loss: 0.0289 - val_acc: 0.9958\n",
      "Epoch 54/100\n",
      "1711/1711 [==============================] - 11s - loss: 5.0567e-04 - acc: 0.9998 - val_loss: 0.0304 - val_acc: 0.9954\n",
      "Epoch 55/100\n",
      "1711/1711 [==============================] - 12s - loss: 4.7661e-04 - acc: 0.9998 - val_loss: 0.0247 - val_acc: 0.9963\n",
      "Epoch 56/100\n",
      "1711/1711 [==============================] - 11s - loss: 4.7731e-04 - acc: 0.9999 - val_loss: 0.0284 - val_acc: 0.9961\n",
      "Epoch 57/100\n",
      "1711/1711 [==============================] - 10s - loss: 4.0103e-04 - acc: 0.9999 - val_loss: 0.0269 - val_acc: 0.9961\n",
      "Epoch 58/100\n",
      "1711/1711 [==============================] - 10s - loss: 4.3204e-04 - acc: 0.9999 - val_loss: 0.0272 - val_acc: 0.9962\n",
      "Epoch 59/100\n",
      "1711/1711 [==============================] - 11s - loss: 4.5109e-04 - acc: 0.9998 - val_loss: 0.0295 - val_acc: 0.9959\n",
      "Epoch 60/100\n",
      "1711/1711 [==============================] - 10s - loss: 3.7618e-04 - acc: 0.9999 - val_loss: 0.0257 - val_acc: 0.9962\n",
      "Epoch 61/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.5693e-04 - acc: 0.9999 - val_loss: 0.0286 - val_acc: 0.9959\n",
      "Epoch 62/100\n",
      "1711/1711 [==============================] - 13s - loss: 4.4610e-04 - acc: 0.9999 - val_loss: 0.0256 - val_acc: 0.9968\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711/1711 [==============================] - 12s - loss: 2.8920e-04 - acc: 0.9999 - val_loss: 0.0273 - val_acc: 0.9962\n",
      "Epoch 64/100\n",
      "1711/1711 [==============================] - 11s - loss: 4.9407e-04 - acc: 0.9998 - val_loss: 0.0270 - val_acc: 0.9963\n",
      "Epoch 65/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.8344e-04 - acc: 0.9999 - val_loss: 0.0257 - val_acc: 0.9963c: 0. - ETA: 7s - loss: 2.8343e-04 - acc: 0.99 - ETA\n",
      "Epoch 66/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.3860e-04 - acc: 0.9999 - val_loss: 0.0315 - val_acc: 0.9961\n",
      "Epoch 67/100\n",
      "1711/1711 [==============================] - 13s - loss: 3.9437e-04 - acc: 0.9999 - val_loss: 0.0261 - val_acc: 0.9964\n",
      "Epoch 68/100\n",
      "1711/1711 [==============================] - 12s - loss: 4.0611e-04 - acc: 0.9999 - val_loss: 0.0255 - val_acc: 0.9963\n",
      "Epoch 69/100\n",
      "1711/1711 [==============================] - 13s - loss: 3.7658e-04 - acc: 0.9999 - val_loss: 0.0282 - val_acc: 0.9959\n",
      "Epoch 70/100\n",
      "1711/1711 [==============================] - 13s - loss: 4.0090e-04 - acc: 0.9998 - val_loss: 0.0282 - val_acc: 0.9961c:\n",
      "Epoch 71/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.6063e-04 - acc: 0.9998 - val_loss: 0.0264 - val_acc: 0.9963\n",
      "Epoch 72/100\n",
      "1711/1711 [==============================] - 11s - loss: 4.0285e-04 - acc: 0.9998 - val_loss: 0.0259 - val_acc: 0.9962\n",
      "Epoch 73/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.0803e-04 - acc: 0.9999 - val_loss: 0.0291 - val_acc: 0.9965\n",
      "Epoch 74/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.3892e-04 - acc: 0.9999 - val_loss: 0.0289 - val_acc: 0.9959\n",
      "Epoch 75/100\n",
      "1711/1711 [==============================] - 11s - loss: 4.5747e-04 - acc: 0.9999 - val_loss: 0.0295 - val_acc: 0.9963\n",
      "Epoch 76/100\n",
      "1711/1711 [==============================] - 10s - loss: 3.9739e-04 - acc: 0.9999 - val_loss: 0.0288 - val_acc: 0.9964\n",
      "Epoch 77/100\n",
      "1711/1711 [==============================] - 10s - loss: 3.9421e-04 - acc: 0.9999 - val_loss: 0.0253 - val_acc: 0.9962\n",
      "Epoch 78/100\n",
      "1711/1711 [==============================] - 10s - loss: 2.7867e-04 - acc: 0.9999 - val_loss: 0.0258 - val_acc: 0.9969\n",
      "Epoch 79/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.2342e-04 - acc: 0.9998 - val_loss: 0.0287 - val_acc: 0.9960\n",
      "Epoch 80/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.3676e-04 - acc: 0.9999 - val_loss: 0.0292 - val_acc: 0.9960\n",
      "Epoch 81/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.3494e-04 - acc: 0.9999 - val_loss: 0.0269 - val_acc: 0.9966\n",
      "Epoch 82/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.1879e-04 - acc: 0.9999 - val_loss: 0.0287 - val_acc: 0.9964\n",
      "Epoch 83/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.1423e-04 - acc: 0.9999 - val_loss: 0.0286 - val_acc: 0.9964\n",
      "Epoch 84/100\n",
      "1711/1711 [==============================] - 14s - loss: 2.8565e-04 - acc: 0.9999 - val_loss: 0.0296 - val_acc: 0.9961\n",
      "Epoch 85/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.4350e-04 - acc: 0.9999 - val_loss: 0.0279 - val_acc: 0.9965\n",
      "Epoch 86/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.1675e-04 - acc: 0.9999 - val_loss: 0.0272 - val_acc: 0.9964\n",
      "Epoch 87/100\n",
      "1711/1711 [==============================] - 10s - loss: 3.0474e-04 - acc: 0.9999 - val_loss: 0.0281 - val_acc: 0.9963\n",
      "Epoch 88/100\n",
      "1711/1711 [==============================] - 11s - loss: 2.5069e-04 - acc: 0.9999 - val_loss: 0.0289 - val_acc: 0.9964\n",
      "Epoch 89/100\n",
      "1711/1711 [==============================] - 10s - loss: 3.1875e-04 - acc: 0.9999 - val_loss: 0.0308 - val_acc: 0.9962\n",
      "Epoch 90/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.1031e-04 - acc: 0.9999 - val_loss: 0.0302 - val_acc: 0.9963\n",
      "Epoch 91/100\n",
      "1711/1711 [==============================] - 11s - loss: 3.0442e-04 - acc: 0.9999 - val_loss: 0.0309 - val_acc: 0.9957\n",
      "Epoch 92/100\n",
      "1711/1711 [==============================] - 13s - loss: 2.9971e-04 - acc: 0.9999 - val_loss: 0.0300 - val_acc: 0.9964\n",
      "Epoch 93/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.4526e-04 - acc: 0.9999 - val_loss: 0.0296 - val_acc: 0.9963\n",
      "Epoch 94/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.0796e-04 - acc: 0.9999 - val_loss: 0.0297 - val_acc: 0.9963\n",
      "Epoch 95/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.1748e-04 - acc: 0.9999 - val_loss: 0.0281 - val_acc: 0.9970\n",
      "Epoch 96/100\n",
      "1711/1711 [==============================] - 12s - loss: 2.8197e-04 - acc: 0.9999 - val_loss: 0.0279 - val_acc: 0.9970\n",
      "Epoch 97/100\n",
      "1711/1711 [==============================] - 13s - loss: 2.8815e-04 - acc: 0.9999 - val_loss: 0.0261 - val_acc: 0.9969\n",
      "Epoch 98/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.7328e-04 - acc: 0.9998 - val_loss: 0.0307 - val_acc: 0.9965\n",
      "Epoch 99/100\n",
      "1711/1711 [==============================] - 12s - loss: 2.2230e-04 - acc: 0.9999 - val_loss: 0.0318 - val_acc: 0.9965\n",
      "Epoch 100/100\n",
      "1711/1711 [==============================] - 12s - loss: 3.1837e-04 - acc: 0.9999 - val_loss: 0.0306 - val_acc: 0.9962\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=100, validation_split=0.1, verbose=1)\n",
    "\n",
    "#model.save('mmmodel.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#modelkk = load_model('mmmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentence = \"An individual wiping command should be implemented by setting the level of WW and INT-line from HIGH to LOW for the parameterized time p_t_einzelwischhub body control module\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newpredict(tt):\n",
    "    result = []\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in tt]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)\n",
    "    p = model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for w, pred in zip(tt, p[0]):\n",
    "        result.append((w, tags[pred]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('An', 'O'),\n",
       " ('individual', 'O'),\n",
       " ('wiping', 'O'),\n",
       " ('command', 'O'),\n",
       " ('should', 'O'),\n",
       " ('be', 'O'),\n",
       " ('implemented', 'O'),\n",
       " ('by', 'O'),\n",
       " ('setting', 'O'),\n",
       " ('the', 'O'),\n",
       " ('level', 'O'),\n",
       " ('of', 'O'),\n",
       " ('WW', 'O'),\n",
       " ('and', 'O'),\n",
       " ('INT-line', 'O'),\n",
       " ('from', 'O'),\n",
       " ('HIGH', 'O'),\n",
       " ('to', 'O'),\n",
       " ('LOW', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('parameterized', 'O'),\n",
       " ('time', 'O'),\n",
       " ('p_t_einzelwischhub', 'O'),\n",
       " ('body', 'O'),\n",
       " ('control', 'O'),\n",
       " ('module', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpredict(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('system', 'Network_Component'),\n",
       " ('should', 'O'),\n",
       " ('do', 'O'),\n",
       " ('the', 'O'),\n",
       " ('validation', 'Action'),\n",
       " ('for', 'O'),\n",
       " ('confirm', 'Action'),\n",
       " ('password', 'Attribute'),\n",
       " ('text', 'O'),\n",
       " ('on', 'O'),\n",
       " ('submit', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('form', 'O')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('The', 'O'),\n",
    " ('system', 'Network_Component'),\n",
    " ('should', 'O'),\n",
    " ('do', 'O'),\n",
    " ('the', 'O'),\n",
    " ('validation', 'Action'),\n",
    " ('for', 'O'),\n",
    " ('confirm', 'Action'),\n",
    " ('password', 'Attribute'),\n",
    " ('text', 'O'),\n",
    " ('on', 'O'),\n",
    " ('submit', 'O'),\n",
    " ('of', 'O'),\n",
    " ('the', 'O'),\n",
    " ('form', 'O')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1902 [============================>.] - ETA: 0sacc: 99.95%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_tr, np.array(y_tr), verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"modelpp6.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"modelpp6.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('modelpp6.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"modelpp6.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jmo4cob\\\\1_ARISE\\\\8_Workshop\\\\NER_workshop'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1902 [============================>.] - ETA: 0sacc: 99.95%\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(X_tr, np.array(y_tr), verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save\n",
    "np.save('word2idx.npy', word2idx) \n",
    "\n",
    "# Load\n",
    "#word2idx = np.load('C:\\\\Users\\\\sharath\\\\Desktop\\\\exp\\\\word2idx.npy').item()\n",
    "\n",
    "\n",
    "# Save\n",
    "np.save('tag2idx.npy', tag2idx) \n",
    "\n",
    "# Load\n",
    "#tag2idx = np.load('C:\\\\Users\\\\sharath\\\\Desktop\\\\exp\\\\tag2idx.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilstmfinal(test_sentence):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from keras.models import model_from_json\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from keras.models import Model, Input\n",
    "    from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.utils import to_categorical\n",
    "    import numpy\n",
    "    numpy.random.seed(7)\n",
    "    word2idx = np.load('word2idx.npy').item()\n",
    "    tag2idx = np.load('tag2idx.npy').item()\n",
    "    # load json and create model\n",
    "    json_file = open('modelpp6.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"modelpp6.h5\")\n",
    "    loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    test_sentence = test_sentence.split(\" \")\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=50)\n",
    "    p = loaded_model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    pls = []\n",
    "    p = loaded_model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for w, pred in zip(test_sentence, p[0]):\n",
    "        pls.append(pred)\n",
    "    revsubs = { v:k for k,v in tag2idx.items()}\n",
    "    entit = [revsubs.get(item,item) for item in pls]\n",
    "    final = list(zip(test_sentence,entit))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"The system shall allow a registered visitor to load a custom filter.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('system', 'O'),\n",
       " ('shall', 'O'),\n",
       " ('allow', 'O'),\n",
       " ('a', 'O'),\n",
       " ('registered', 'actor'),\n",
       " ('visitor', 'actor'),\n",
       " ('to', 'O'),\n",
       " ('load', 'action'),\n",
       " ('a', 'O'),\n",
       " ('custom', 'attribute'),\n",
       " ('filter.', 'O')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstmfinal(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def lstm_model():\n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "#     from keras.models import load_model\n",
    "\n",
    "\n",
    "#     data = pd.read_csv('C:\\\\users\\\\sharath\\\\postags_v1.csv', encoding='latin1', sep = ',')\n",
    "#     data = data.fillna(method=\"ffill\")\n",
    "#     words = list(set(data[\"Word\"].values))\n",
    "#     words.append(\"ENDPAD\")\n",
    "#     n_words = len(words)\n",
    "#     tags = list(set(data[\"Tag\"].values))\n",
    "#     n_tags = len(tags)\n",
    "\n",
    "#     class SentenceGetter(object):\n",
    "\n",
    "#         def __init__(self, data):\n",
    "#             self.n_sent = 1\n",
    "#             self.data = data\n",
    "#             self.empty = False\n",
    "#             agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "#                                                                s[\"POS\"].values.tolist(),\n",
    "#                                                                s[\"Tag\"].values.tolist())]\n",
    "#             self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "#             self.sentences = [s for s in self.grouped]\n",
    "\n",
    "#         def get_next(self):\n",
    "#             try:\n",
    "#                 s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "#                 self.n_sent += 1\n",
    "#                 return s\n",
    "#             except:\n",
    "#                 return None\n",
    "\n",
    "#     getter = SentenceGetter(data)\n",
    "#     sent = getter.get_next()\n",
    "#     sentences = getter.sentences\n",
    "#     max_len = 50\n",
    "#     word2idx = {w: i for i, w in enumerate(words)}\n",
    "#     tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "#     from keras.preprocessing.sequence import pad_sequences\n",
    "#     X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "#     X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "#     y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "#     y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "#     from keras.utils import to_categorical\n",
    "#     y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "#     X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "#     from keras.models import Model, Input\n",
    "#     from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "#     input = Input(shape=(max_len,))\n",
    "#     model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(input)\n",
    "#     model = Dropout(0.1)(model)\n",
    "#     model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "#     out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer\n",
    "#     model = Model(input, out)\n",
    "#     model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#     history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n",
    "#     history.model.save('m3odel.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#     del model  # deletes the existing model\n",
    "#     # returns a compiled model\n",
    "#     # identical to the previous one\n",
    "#     modelkk = load_model('m3odel.h5')\n",
    "#     return modelkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x1ba7dc0d0f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = \"The system shall allow the data manager to search occurrence resources by keywords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = \"The system shall allow the data manager to edit the metadata of an institution resource\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
